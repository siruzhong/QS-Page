---
layout: default
title : LLM & AI Agent
navbar_title: LLM & AI Agent
permalink: /llm-ai-agent.html
---

<div class="row">
    <div class="col-12 col-lg-10">        
        <h3 class="pt-4">Research on LLM & AI Agent</h3>
        <div class="mt-3">
            <p><em>(for LLM & AI Agent in Time Series and Education domains, check <a href="/ai-for-time-series">AI for Time Series</a>, <a href="/ai-for-education">AI for Education</a>)</em></p>
            <p><strong>Algorithm & Benchmark & Data & Code:</strong></p>
            <ul style="font-size: 15px;">
                <li>[<strong style="color: #4a86e8;">KDD'26</strong>] Evaluating RAG Robustness to Symbolic Perturbations, <strong style="color: #4a86e8;">KDD 2026</strong>.</li>
                <li>[<strong style="color: #4a86e8;">AAAI'26</strong>] Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation, <strong style="color: #4a86e8;">AAAI 2026</strong>. [<a href="#" target="_blank">arXiv</a>] (<strong style="color: red;">AAAI Oral, Top 5%</strong>)</li>
                <li>[<strong style="color: #4a86e8;">AAAI'26</strong>] SafeSieve: From Heuristics to Experience in Progressive Pruning for LLM-based Multi-Agent Communication, <strong style="color: #4a86e8;">AAAI 2026</strong>. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[<strong style="color: red;">NeurIPS'25</strong>] Improving Nonlinear RNN with Closed-loop Control, <strong style="color: red;">NeurIPS 2025</strong>. [<a href="#" target="_blank">arXiv</a>] (<strong style="color: red;">NeurIPS Spotlight, Top 3.5%</strong>)</li>
                <li>[<strong style="color: red;">NeurIPS'25</strong>] Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs, <strong style="color: red;">NeurIPS 2025</strong>.</li>
                <li>[<strong style="color: red;">NeurIPS'25</strong>] SAEMark: Steering Personalized Multilingual LLM Watermarks with Sparse Autoencoders, <strong style="color: red;">NeurIPS 2025</strong>.</li>
                <li>[<strong style="color: red;">ICLR'25</strong>] MME-RealWorld: Could Your Multimodal LLM Challenge High-Resolution Real-World Scenarios that are Difficult for Humans? <strong style="color: red;">ICLR 2025</strong>. [<a href="#" target="_blank">arXiv</a>] [<a href="#" target="_blank">code</a>]</li>
                <li>[<strong style="color: red;">NeurIPS'24</strong>] AutoSurvey: Large Language Models Can Automatically Write Surveys, <strong style="color: red;">NeurIPS 2024</strong> [<a href="#" target="_blank">arXiv</a>] [<a href="#" target="_blank">code</a>]</li>
                <li>[<strong style="color: #4a86e8;">ACL'25</strong>] NetSafe: Exploring the Topological Safety of Multi-agent Networks, <strong style="color: #4a86e8;">ACL 2025</strong>. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[<strong style="color: #4a86e8;">EMNLP'25</strong>] DynamicNER: A Dynamic, Multilingual, and Fine-Grained Dataset for LLM-based Named Entity Recognition, <strong style="color: #4a86e8;">EMNLP 2025</strong>. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[<strong style="color: #4a86e8;">AAAI'25</strong>] UrbanVLP: Multi-Granularity Vision-Language Pretraining for Urban Socioeconomic Indicator Prediction, <strong style="color: #4a86e8;">AAAI 2025</strong> [<a href="#" target="_blank">paper</a>]</li>
                <li>[<strong style="color: #4a86e8;">MM'25</strong>] The Eye of Sherlock Holmes: Uncovering User Private Attribute Profiling via Vision-Language Model Agentic Framework, <strong style="color: #4a86e8;">ACM MM 2025</strong>. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[<strong style="color: #4a86e8;">MM'25</strong>] Debiasing Multimodal Large Language Models via Penalization of Language Priors, <strong style="color: #4a86e8;">ACM MM 2025</strong>. [<a href="#" target="_blank">arXiv</a>] [<a href="#" target="_blank">code</a>]</li>
                <li>[<strong style="color: #4a86e8;">WWW'24</strong>] UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web, <strong style="color: #4a86e8;">WWW '24</strong> [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[<strong style="color: #4a86e8;">EMNLP'24</strong>] RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation, <strong style="color: #4a86e8;">EMNLP 2024</strong> (Demo Track) [<a href="#" target="_blank">arXiv</a>] [<a href="#" target="_blank">code</a>]</li>
                <li>[arXiv'24] Beyond LLaVA-HD: Diving into High-Resolution Large Multimodal Models, arXiv 2024. [<a href="#" target="_blank">arXiv</a>] [<a href="#" target="_blank">code</a>]</li>
                <li>[arXiv'25] LLM-Virus: Evolutionary Jailbreak Attack on Large Language Models, arXiv 2025. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[arXiv'25] AgentSafe: Safeguarding Large Language Model-based Multi-agent Systems via Hierarchical Data Management, arXiv 2025. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[arXiv'25] Automating Personalization: Prompt Optimization for Recommendation Reranking, arXiv 2025. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[arXiv'25] DiffuGuard: How Intrinsic Safety is Lost and Found in Diffusion Large Language Models, arXiv 2025. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[arXiv'25] Backdoor Attribution: Elucidating and Controlling Backdoor in Language Models, arXiv 2025. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[arXiv'25] ARM2: Adaptive Reasoning Model with Vision Understanding and Executable Code, arXiv 2025. [<a href="#" target="_blank">arXiv</a>]</li>
            </ul>
        </div>

        <h3 class="pt-4">Survey & Position & Perspective</h3>
        <div class="mt-3">
            <ul style="font-size: 15px;">
                <li>[<strong style="color: red;">SPM'25</strong>] Brain Foundation Models: A Survey on Advancements in Neural Signal Processing and Brain Discovery, <strong style="color: red;">IEEE Signal Processing Magazine</strong>, 2025. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[<strong style="color: #4a86e8;">ACL'25</strong>] A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges, <strong style="color: #4a86e8;">ACL 2025</strong>. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[<strong style="color: #4a86e8;">FnTs'25</strong>] Recommender Systems Meet Large Language Model Agents: A Survey, <strong style="color: #4a86e8;">Foundations and TrendsÂ® in Privacy and Security</strong>, 2025. [<a href="#" target="_blank">link</a>] [<a href="#" target="_blank">Preprint</a>]</li>
                <li>[<strong style="color: #4a86e8;">KDD'25</strong>] A Survey on Trustworthy LLM Agents: Threats and Countermeasures, <strong style="color: #4a86e8;">KDD 2025</strong>. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[arXiv'25] A comprehensive survey in llm (-agent) full stack safety: Data, training and deployment, arXiv 2025. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[arXiv'25] Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning, arXiv 2025. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[arXiv'25] Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems, arXiv 2025. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[arXiv'25] Aligning Multimodal LLM with Human Preference: A Survey, arXiv 2025. [<a href="#" target="_blank">arXiv</a>]</li>
                <li>[arXiv'25] A Survey on Post-training of Large Language Models, arXiv 2025. [<a href="#" target="_blank">arXiv</a>]</li>
            </ul>
        </div>

        <h3 class="pt-4">Workshop on AI Agent (@ KDD, WWW, CIKM, AAAI)</h3>
        <div class="mt-3">
            <ul style="font-size: 15px;">
                <li>KDD Workshop on AI Agent for Information Retrieval (KDD'25-Agent4IR)</li>
                <li>WWW Workshop on AI Agent for Information Retrieval: Generating and Ranking (<a href="https://sites.google.com/view/ai4ir/www-2025" target="_blank">WWW'25-Agent4IR</a>)</li>
                <li>AAAI Workshop on AI Agent for Information Retrieval: Generating and Ranking (<a href="https://sites.google.com/view/ai4ir/aaai-2025" target="_blank">AAAI'25-Agent4IR</a>)</li>
                <li>CIKM Workshop on AI Agent for Information Retrieval (<a href="https://sites.google.com/view/ai4ir/cikm-2024" target="_blank">CIKM'24-Agent4IR</a>)</li>
            </ul>
        </div>
    </div>
</div>
